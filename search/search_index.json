{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"competition-overview/","text":"Competition Overview Robotics and AI is revolutionizing the what and how we work today and will continue in the future. Today, robots are augmenting the capability of human workers in various industries: logistics, healthcare, agriculture, etc. The PARC Engineers league tasks participants to reimagine how humans can augment the capabilities of intelligent robots in a task of growing prevalence - autonomous parcel delivery. The challenge of the competition is to build software to operate a wheeled mobile robot to complete a delivery task including: navigating through a sidewalk, crossing the road using a crosswalk and navigating in a park to find the drop location. This competition would consist two phases: a simulation phase and a physical robot phase. Simulation Phase In this phase, teams would interact with the delivery robot in simulation (using the Gazebo Robot Simulator). Participants are required to write software to complete three crucial tasks for the operation of a delivery robot: Sidewalk following (with obstacle avoidance) Traffic sign detection and recognition Go-to-goal navigation (with obstacle avoidance) Participating teams will follow the instructions in this documentation to set up their PCs and download the complete simulation packages required to complete the tasks. Teams are required to complete and upload their solutions on or before the Phase 1 deadline. Following team evaluations, teams with the best solutions will qualify to compete in Phase 2. Physical Robot Phase In this phase, the qualified teams get a chance to refine and deploy their software on the physical robot to compete on the main competition day. First, a complete simulation of the competition environment would be provided to teams to integrate and their solutions from Phase 1. The task here is to operate the delivery robot to complete a delivery by moving from parcel pickup location to the drop-off location. Once satisfactory results are achieved in simulation, participants would be allowed to test their software on the physical robot virtually by reserving time on our booking calendar [to be provided]. To be allowed to compete on the final competition, teams must submit a report (including videos of their fully functional solution in simulation) and upload their code for review. Competition Prizes The 1st place winner: $2,000 Other awards for top teams include prizes from sponsors such as laptops, tablets mentoring! How to Participate Prospective teams would be required to complete an online application and fill out a team profile form Important Dates Event Date Registration Opens February 20th 2021 Registration Deadline March 20th 2021 Phase 1 Submission Deadline May 16th 2021 Phase 2 Qualification Announcement May 28th 2021 Phase 2 Submission Deadline July 2nd 2021 Final Competition Days July 9th-11th 2021","title":"Competition Overview"},{"location":"competition-overview/#competition_overview","text":"Robotics and AI is revolutionizing the what and how we work today and will continue in the future. Today, robots are augmenting the capability of human workers in various industries: logistics, healthcare, agriculture, etc. The PARC Engineers league tasks participants to reimagine how humans can augment the capabilities of intelligent robots in a task of growing prevalence - autonomous parcel delivery. The challenge of the competition is to build software to operate a wheeled mobile robot to complete a delivery task including: navigating through a sidewalk, crossing the road using a crosswalk and navigating in a park to find the drop location. This competition would consist two phases: a simulation phase and a physical robot phase.","title":"Competition Overview"},{"location":"competition-overview/#simulation_phase","text":"In this phase, teams would interact with the delivery robot in simulation (using the Gazebo Robot Simulator). Participants are required to write software to complete three crucial tasks for the operation of a delivery robot: Sidewalk following (with obstacle avoidance) Traffic sign detection and recognition Go-to-goal navigation (with obstacle avoidance) Participating teams will follow the instructions in this documentation to set up their PCs and download the complete simulation packages required to complete the tasks. Teams are required to complete and upload their solutions on or before the Phase 1 deadline. Following team evaluations, teams with the best solutions will qualify to compete in Phase 2.","title":"Simulation Phase"},{"location":"competition-overview/#physical_robot_phase","text":"In this phase, the qualified teams get a chance to refine and deploy their software on the physical robot to compete on the main competition day. First, a complete simulation of the competition environment would be provided to teams to integrate and their solutions from Phase 1. The task here is to operate the delivery robot to complete a delivery by moving from parcel pickup location to the drop-off location. Once satisfactory results are achieved in simulation, participants would be allowed to test their software on the physical robot virtually by reserving time on our booking calendar [to be provided]. To be allowed to compete on the final competition, teams must submit a report (including videos of their fully functional solution in simulation) and upload their code for review.","title":"Physical Robot Phase"},{"location":"competition-overview/#competition_prizes","text":"The 1st place winner: $2,000 Other awards for top teams include prizes from sponsors such as laptops, tablets mentoring!","title":"Competition Prizes"},{"location":"competition-overview/#how_to_participate","text":"Prospective teams would be required to complete an online application and fill out a team profile form","title":"How to Participate"},{"location":"competition-overview/#important_dates","text":"Event Date Registration Opens February 20th 2021 Registration Deadline March 20th 2021 Phase 1 Submission Deadline May 16th 2021 Phase 2 Qualification Announcement May 28th 2021 Phase 2 Submission Deadline July 2nd 2021 Final Competition Days July 9th-11th 2021","title":"Important Dates"},{"location":"faqs/","text":"Frequently Asked Questions Who is eligible to compete? University Students Young Professionals, ages 18+. Teams must have 2-8 members. What specific skills does my team need to compete? Basic knowledge of Python or C++. What skills will my team enhance through participating in PARC? Developing robotic software in ROS Strengthen programming skills Real world robotics problem solving Implement computer vision solutions How does my team register to compete and when is the deadline? Visit www.parcrobotics.org to register to compete, the competition begins Feb 20, 2021 but the deadline to register is March 20, 2021. My team has registered, how do we get started? Teams receive the PARC 2021 Challenge and the \"Getting Started\" instructions to set up their computer and begin coding their solution. Do you have a question not addressed above, send your question to us here","title":"Frequently Asked Questions"},{"location":"faqs/#frequently_asked_questions","text":"Who is eligible to compete? University Students Young Professionals, ages 18+. Teams must have 2-8 members. What specific skills does my team need to compete? Basic knowledge of Python or C++. What skills will my team enhance through participating in PARC? Developing robotic software in ROS Strengthen programming skills Real world robotics problem solving Implement computer vision solutions How does my team register to compete and when is the deadline? Visit www.parcrobotics.org to register to compete, the competition begins Feb 20, 2021 but the deadline to register is March 20, 2021. My team has registered, how do we get started? Teams receive the PARC 2021 Challenge and the \"Getting Started\" instructions to set up their computer and begin coding their solution. Do you have a question not addressed above, send your question to us here","title":"Frequently Asked Questions"},{"location":"forum/","text":"Note Follow this link to join the PARC2021 Engineers League Forum. You can use the forum to ask questions and discuss topics related to PARC2021 Enigneers League.","title":"Q & A Forum"},{"location":"getting-started/getting-started-with-ros/understanding-ros/","text":"Getting started with ROS The Robot Operating System (ROS) is a flexible framework for writing robot software. It is a collection of tools, libraries, and conventions that aim to simplify the task of creating complex and robust robot behavior across a wide variety of robotic platforms. We have planned this competition around ROS because of its features as well as its widespread use in robotics research and industry. To get started with ROS (if you are a beginner), we recommend you follow the \"Beginner Level\" tutorials in the official ROS Tutorials . Ensure you complete at least the following: Chapter 5 (ROS Nodes): \"This tutorial introduces ROS graph concepts and discusses the use of roscore, rosnode, and rosrun commandline tools\" Chapter 6 (ROS Topics): \"This tutorial introduces ROS topics as well as using the rostopic and rqt_plot commandline tools.\" Chapter 12 (Writing simple publisher and subscriber in Python) Understand the core tools provided by ROS , including RViz, rqt_graph, Gazebo, etc. After you complete the required tutorials listed above, you can start setting up the workspace . Assuming the workspace at ~/catkin_ws/ as completed from the steps done in setting up your workspace , This should be your folder structure till now. ~/catkin_ws/ \u251c\u2500\u2500 build/ \u2502 \u251c\u2500\u2500 . \u2502 \u2514\u2500\u2500 . \u251c\u2500\u2500 devel/ \u2502 \u251c\u2500\u2500 . \u2502 \u2514\u2500\u2500 . \u2514\u2500\u2500 src/ \u251c\u2500\u2500 CMakeLists.txt \u2514\u2500\u2500 parc-engineers-league/ \u251c\u2500\u2500 parc-robot/ \u2502 \u251c\u2500\u2500 . \u2502 \u251c\u2500\u2500 . \u2502 \u251c\u2500\u2500 CMakeLists.txt \u2502 \u2514\u2500\u2500 package.xml \u251c\u2500\u2500 . \u2514\u2500\u2500 . First step is to create your solution folder in ~/catkin_ws/src/ , we can call it parc_solutions for example. mkdir ~/catkin_ws/src/parc_solutions Go inside the folder, cd ~/catkin_ws/src/parc_solutions And here you can create a new ROS package called test_publisher (for example) by running the command below, catkin_create_pkg test_publisher roscpp rospy std_msgs geometry_msgs Moving the Robot Programmically Setting up your workspace guide has already shown how to control the robot with keyboard using teleoperation But this guide will help you to move the robot by publishing commands to /cmd_vel topic programmically using a Python script. To do this, create a file, robot_publisher.py inside scripts folder in your ROS package (for example test_publisher ) and make it executable. mkdir test_publisher/scripts touch test_publisher/scripts/robot_publisher.py chmod +x test_publisher/scripts/robot_publisher.py NOTE: You need to change the permission of the file to executable to be able to run (as done in the last command shown above). Now open the file and copy and paste the following code inside: #!/usr/bin/env python Script to move Robot import rospy from geometry_msgs.msg import Twist import time def move_robot(): rospy.init_node('robot_publisher', anonymous=True) # Create a publisher which can talk to Robot and tell it to move pub = rospy.Publisher('/cmd_vel', Twist, queue_size=10) # Set publish rate at 10 Hz rate = rospy.Rate(10) # Create a Twist message and add linear x and angular z values move_cmd = Twist() ######## Move Straight ######## print( Moving Straight ) move_cmd.linear.x = 0.5 # move in X axis at 0.5 m/s move_cmd.angular.z = 0.0 now = time.time() # For the next 4 seconds publish cmd_vel move commands while time.time() - now 4: pub.publish(move_cmd) # publish to Robot rate.sleep() ######## Rotating Counterclockwise ######## print( Rotating ) move_cmd.linear.x = 0.0 move_cmd.angular.z = 0.3 # rotate at 0.3 rad/sec now = time.time() # For the next 3 seconds publish cmd_vel move commands while time.time() - now 3: pub.publish(move_cmd) # publish to Robot rate.sleep() ######## Stop ######## print( Stopping ) move_cmd.linear.x = 0.0 move_cmd.angular.z = 0.0 # Giving both zero will stop the robot now = time.time() # For the next 1 seconds publish cmd_vel move commands while time.time() - now 1: pub.publish(move_cmd) # publish to Robot rate.sleep() print( Exit ) if __name__ == '__main__': try: move_robot() except rospy.ROSInterruptException: pass This code will make the robot move straight for 4 seconds, rotate counterclockwise for 3 seconds and then stop. To see it working, first run the robot in simulation by running the following command in one terminal source ~/catkin_ws/devel/setup.bash roslaunch parc-robot task1.launch And run the following command in another terminal to run this new program: source ~/catkin_ws/devel/setup.bash rosrun test_publisher robot_publisher.py If you have set up everything well, you should see the robot moving in Gazebo as below:","title":"Getting started with ROS"},{"location":"getting-started/getting-started-with-ros/understanding-ros/#getting_started_with_ros","text":"The Robot Operating System (ROS) is a flexible framework for writing robot software. It is a collection of tools, libraries, and conventions that aim to simplify the task of creating complex and robust robot behavior across a wide variety of robotic platforms. We have planned this competition around ROS because of its features as well as its widespread use in robotics research and industry. To get started with ROS (if you are a beginner), we recommend you follow the \"Beginner Level\" tutorials in the official ROS Tutorials . Ensure you complete at least the following: Chapter 5 (ROS Nodes): \"This tutorial introduces ROS graph concepts and discusses the use of roscore, rosnode, and rosrun commandline tools\" Chapter 6 (ROS Topics): \"This tutorial introduces ROS topics as well as using the rostopic and rqt_plot commandline tools.\" Chapter 12 (Writing simple publisher and subscriber in Python) Understand the core tools provided by ROS , including RViz, rqt_graph, Gazebo, etc. After you complete the required tutorials listed above, you can start setting up the workspace . Assuming the workspace at ~/catkin_ws/ as completed from the steps done in setting up your workspace , This should be your folder structure till now. ~/catkin_ws/ \u251c\u2500\u2500 build/ \u2502 \u251c\u2500\u2500 . \u2502 \u2514\u2500\u2500 . \u251c\u2500\u2500 devel/ \u2502 \u251c\u2500\u2500 . \u2502 \u2514\u2500\u2500 . \u2514\u2500\u2500 src/ \u251c\u2500\u2500 CMakeLists.txt \u2514\u2500\u2500 parc-engineers-league/ \u251c\u2500\u2500 parc-robot/ \u2502 \u251c\u2500\u2500 . \u2502 \u251c\u2500\u2500 . \u2502 \u251c\u2500\u2500 CMakeLists.txt \u2502 \u2514\u2500\u2500 package.xml \u251c\u2500\u2500 . \u2514\u2500\u2500 . First step is to create your solution folder in ~/catkin_ws/src/ , we can call it parc_solutions for example. mkdir ~/catkin_ws/src/parc_solutions Go inside the folder, cd ~/catkin_ws/src/parc_solutions And here you can create a new ROS package called test_publisher (for example) by running the command below, catkin_create_pkg test_publisher roscpp rospy std_msgs geometry_msgs","title":"Getting started with ROS"},{"location":"getting-started/getting-started-with-ros/understanding-ros/#moving_the_robot_programmically","text":"Setting up your workspace guide has already shown how to control the robot with keyboard using teleoperation But this guide will help you to move the robot by publishing commands to /cmd_vel topic programmically using a Python script. To do this, create a file, robot_publisher.py inside scripts folder in your ROS package (for example test_publisher ) and make it executable. mkdir test_publisher/scripts touch test_publisher/scripts/robot_publisher.py chmod +x test_publisher/scripts/robot_publisher.py NOTE: You need to change the permission of the file to executable to be able to run (as done in the last command shown above). Now open the file and copy and paste the following code inside: #!/usr/bin/env python Script to move Robot import rospy from geometry_msgs.msg import Twist import time def move_robot(): rospy.init_node('robot_publisher', anonymous=True) # Create a publisher which can talk to Robot and tell it to move pub = rospy.Publisher('/cmd_vel', Twist, queue_size=10) # Set publish rate at 10 Hz rate = rospy.Rate(10) # Create a Twist message and add linear x and angular z values move_cmd = Twist() ######## Move Straight ######## print( Moving Straight ) move_cmd.linear.x = 0.5 # move in X axis at 0.5 m/s move_cmd.angular.z = 0.0 now = time.time() # For the next 4 seconds publish cmd_vel move commands while time.time() - now 4: pub.publish(move_cmd) # publish to Robot rate.sleep() ######## Rotating Counterclockwise ######## print( Rotating ) move_cmd.linear.x = 0.0 move_cmd.angular.z = 0.3 # rotate at 0.3 rad/sec now = time.time() # For the next 3 seconds publish cmd_vel move commands while time.time() - now 3: pub.publish(move_cmd) # publish to Robot rate.sleep() ######## Stop ######## print( Stopping ) move_cmd.linear.x = 0.0 move_cmd.angular.z = 0.0 # Giving both zero will stop the robot now = time.time() # For the next 1 seconds publish cmd_vel move commands while time.time() - now 1: pub.publish(move_cmd) # publish to Robot rate.sleep() print( Exit ) if __name__ == '__main__': try: move_robot() except rospy.ROSInterruptException: pass This code will make the robot move straight for 4 seconds, rotate counterclockwise for 3 seconds and then stop. To see it working, first run the robot in simulation by running the following command in one terminal source ~/catkin_ws/devel/setup.bash roslaunch parc-robot task1.launch And run the following command in another terminal to run this new program: source ~/catkin_ws/devel/setup.bash rosrun test_publisher robot_publisher.py If you have set up everything well, you should see the robot moving in Gazebo as below:","title":"Moving the Robot Programmically"},{"location":"getting-started/setting-up-your-pc/","text":"How to setup the Computer This guide helps you setup your computer for running the competition environment locally and developing the code. You can use local Computer/Laptop or Virtual Machine inside your computer or any cloud platform like Google GCP , Amazon AWS , Microsoft Azure , Digital Ocean , etc (All Cloud providers have some free trial plan which you can make use of). System requirements The competition setup needs to be run on Ubuntu , a flavor of Linux . You will need a computer that has: A dedicated GPU , Nvidia cards tend to work well in Ubuntu A CPU that is at least an Intel i5, or equivalent, At least 4GB of free disk space, At least 8GB of RAM, Ubuntu Xenial installed. Operating System If not already installed, Install Ubuntu Bionic (18.04) on the system by following this guide . Note It is highly recommended to install Bionic (18.04) version of Ubuntu due to ROS (Melodic) dependency. Installing ROS You need to install ROS Melodic by following this guide and install ros-melodic-desktop-full in the step 1.4 of the guide.","title":"Setting up your PC"},{"location":"getting-started/setting-up-your-pc/#how_to_setup_the_computer","text":"This guide helps you setup your computer for running the competition environment locally and developing the code. You can use local Computer/Laptop or Virtual Machine inside your computer or any cloud platform like Google GCP , Amazon AWS , Microsoft Azure , Digital Ocean , etc (All Cloud providers have some free trial plan which you can make use of).","title":"How to setup the Computer"},{"location":"getting-started/setting-up-your-pc/#system_requirements","text":"The competition setup needs to be run on Ubuntu , a flavor of Linux . You will need a computer that has: A dedicated GPU , Nvidia cards tend to work well in Ubuntu A CPU that is at least an Intel i5, or equivalent, At least 4GB of free disk space, At least 8GB of RAM, Ubuntu Xenial installed.","title":"System requirements"},{"location":"getting-started/setting-up-your-pc/#operating_system","text":"If not already installed, Install Ubuntu Bionic (18.04) on the system by following this guide . Note It is highly recommended to install Bionic (18.04) version of Ubuntu due to ROS (Melodic) dependency.","title":"Operating System"},{"location":"getting-started/setting-up-your-pc/#installing_ros","text":"You need to install ROS Melodic by following this guide and install ros-melodic-desktop-full in the step 1.4 of the guide.","title":"Installing ROS"},{"location":"getting-started/setting-up-your-workspace/","text":"How to set up your workspace In this tutorial, you will set your set up a directory on your ROS-enabled PC as your workspace for development and install the competition ROS packages. Please follow the instructions below carefully. Note This can ONLY be completed after you have set up your PC (by following the previous tutorial) Setup ROS workspace Open a new terminal on your PC, then copy and paste the following one line at a time: mkdir -p ~/catkin_ws/src cd ~/catkin_ws/src catkin_init_workspace Clone the repository In the same terminal (or in a new one), copy and paste the following: cd ~/catkin_ws/src git clone --recurse-submodules https://github.com/PARC-Robotics/PARC-Engineers-League.git Or if you already have cloned the repo without submodules, run command git submodule update --init --recursive to update them. Install dependencies In the same terminal (or in a new one), copy and paste the following: cd ~/catkin_ws sudo apt update rosdep install --from-paths ./src --ignore-src -y Compile packages cd ~/catkin_ws catkin_make source ~/catkin_ws/devel/setup.bash NOTE: There is a known issue while compiling, Intel RealSense SDK 2.0 is missing To solve, update the file realsense-ros/realsense_camera/CMakeLists.txt ,line: 43 to find_package(realsense2 2.36.0) i.e. downgrade the required version of realsense2 to 2.36.0 Set up ROS environment To set the environment every time you launch a new terminal, following this command: echo source ~/catkin_ws/devel/setup.bash ~/.bashrc source ~/.bashrc As you develop, it is good to set the environment variables whenever you run a catkin_make command to compile changes to your packages. You can do that by: source ~/catkin_ws/devel/setup.bash Test installation If you completed the preceding tasks successfully, you should be able to run this ROS launch command and see the Gazebo simulator and RViz simulator open with the following display: roslaunch parc-robot task1.launch Gazebo Simulator window RViz window If you run the following command in a new terminal, rqt_graph You will see a screen like this: You need to publish /write to the topic /cmd_vel to move the robot. The following guide will help you control the robot using keyboard. Once you have tested that, you can follow the understanding-ros guide to write a python program to control the robot. Controlling the robot using keyboard Run the following command in a new terminal source ~/catkin_ws/devel/setup.bash roslaunch parc-robot teleop.launch Now keeping the second terminal on top (teleop.launch) press i to move the robot forward, you can see the robot moving in \"RViz\" and \"Gazebo\" windows. you can use the keys shown below to move the robot and k key to stop the movement. Moving around: u i o j k l m , .","title":"Setting up your Workspace"},{"location":"getting-started/setting-up-your-workspace/#how_to_set_up_your_workspace","text":"In this tutorial, you will set your set up a directory on your ROS-enabled PC as your workspace for development and install the competition ROS packages. Please follow the instructions below carefully. Note This can ONLY be completed after you have set up your PC (by following the previous tutorial)","title":"How to set up your workspace"},{"location":"getting-started/setting-up-your-workspace/#setup_ros_workspace","text":"Open a new terminal on your PC, then copy and paste the following one line at a time: mkdir -p ~/catkin_ws/src cd ~/catkin_ws/src catkin_init_workspace","title":"Setup ROS workspace"},{"location":"getting-started/setting-up-your-workspace/#clone_the_repository","text":"In the same terminal (or in a new one), copy and paste the following: cd ~/catkin_ws/src git clone --recurse-submodules https://github.com/PARC-Robotics/PARC-Engineers-League.git Or if you already have cloned the repo without submodules, run command git submodule update --init --recursive to update them.","title":"Clone the repository"},{"location":"getting-started/setting-up-your-workspace/#install_dependencies","text":"In the same terminal (or in a new one), copy and paste the following: cd ~/catkin_ws sudo apt update rosdep install --from-paths ./src --ignore-src -y","title":"Install dependencies"},{"location":"getting-started/setting-up-your-workspace/#compile_packages","text":"cd ~/catkin_ws catkin_make source ~/catkin_ws/devel/setup.bash NOTE: There is a known issue while compiling, Intel RealSense SDK 2.0 is missing To solve, update the file realsense-ros/realsense_camera/CMakeLists.txt ,line: 43 to find_package(realsense2 2.36.0) i.e. downgrade the required version of realsense2 to 2.36.0","title":"Compile packages"},{"location":"getting-started/setting-up-your-workspace/#set_up_ros_environment","text":"To set the environment every time you launch a new terminal, following this command: echo source ~/catkin_ws/devel/setup.bash ~/.bashrc source ~/.bashrc As you develop, it is good to set the environment variables whenever you run a catkin_make command to compile changes to your packages. You can do that by: source ~/catkin_ws/devel/setup.bash","title":"Set up ROS environment"},{"location":"getting-started/setting-up-your-workspace/#test_installation","text":"If you completed the preceding tasks successfully, you should be able to run this ROS launch command and see the Gazebo simulator and RViz simulator open with the following display: roslaunch parc-robot task1.launch Gazebo Simulator window RViz window If you run the following command in a new terminal, rqt_graph You will see a screen like this: You need to publish /write to the topic /cmd_vel to move the robot. The following guide will help you control the robot using keyboard. Once you have tested that, you can follow the understanding-ros guide to write a python program to control the robot.","title":"Test installation"},{"location":"getting-started/setting-up-your-workspace/#controlling_the_robot_using_keyboard","text":"Run the following command in a new terminal source ~/catkin_ws/devel/setup.bash roslaunch parc-robot teleop.launch Now keeping the second terminal on top (teleop.launch) press i to move the robot forward, you can see the robot moving in \"RViz\" and \"Gazebo\" windows. you can use the keys shown below to move the robot and k key to stop the movement. Moving around: u i o j k l m , .","title":"Controlling the robot using keyboard"},{"location":"phase1-instructions/","text":"Phase 1: Simulation In this simulation-only phase, teams would work on providing solutions to three (3) fundamental tasks of a delivery robot which are: Sidewalk following (with obstacle avoidance) Traffic sign detection and recognition Go-to-goal navigation (with obstacle avoidance) The simulation platform to be used in this phase is the Gazebo Simulator . Teams are required to develop, test and submit software to successfully complete these tasks autonomously. This phase will evaluate the teams' capabilities to successfully complete these fundamental tasks required to compete in phase 2 (on the physical robot). Each task is designed as stand-alone, not depending on other task functionalities, hence, we request teams to complete the tasks separately. The tasks would be evaluated individually and the total team score for this phase would be the sum of individual task scores. Teams are provided with the delivery robot ROS packages and Gazebo environment models (see description below) to enable them develop and test their solutions (see GitHub Repository ). Delivery Robot The delivery robot is an unmanned ground vehicle (UGV) fitted with 2D LiDAR (light detection and ranging or laser scanner) and an RGB-Depth camera. The figure below shows the delivey robot with sensors labelled. Simulation Environment The simulation environment used in this phase is modeled as a realistic street with roads, sidewalk, crosswalk, traffic signals and buildings. The sidewalk is fitted with lane markings to ease the task of sidewalk following. The goal of the competition is to pick up a parcel from the store (side of the building) and deliver it to the person in the park. The figure below shows the simulation environment with labels of significant objects.","title":"Introduction"},{"location":"phase1-instructions/#phase_1_simulation","text":"In this simulation-only phase, teams would work on providing solutions to three (3) fundamental tasks of a delivery robot which are: Sidewalk following (with obstacle avoidance) Traffic sign detection and recognition Go-to-goal navigation (with obstacle avoidance) The simulation platform to be used in this phase is the Gazebo Simulator . Teams are required to develop, test and submit software to successfully complete these tasks autonomously. This phase will evaluate the teams' capabilities to successfully complete these fundamental tasks required to compete in phase 2 (on the physical robot). Each task is designed as stand-alone, not depending on other task functionalities, hence, we request teams to complete the tasks separately. The tasks would be evaluated individually and the total team score for this phase would be the sum of individual task scores. Teams are provided with the delivery robot ROS packages and Gazebo environment models (see description below) to enable them develop and test their solutions (see GitHub Repository ).","title":"Phase 1: Simulation"},{"location":"phase1-instructions/#delivery_robot","text":"The delivery robot is an unmanned ground vehicle (UGV) fitted with 2D LiDAR (light detection and ranging or laser scanner) and an RGB-Depth camera. The figure below shows the delivey robot with sensors labelled.","title":"Delivery Robot"},{"location":"phase1-instructions/#simulation_environment","text":"The simulation environment used in this phase is modeled as a realistic street with roads, sidewalk, crosswalk, traffic signals and buildings. The sidewalk is fitted with lane markings to ease the task of sidewalk following. The goal of the competition is to pick up a parcel from the store (side of the building) and deliver it to the person in the park. The figure below shows the simulation environment with labels of significant objects.","title":"Simulation Environment"},{"location":"phase1-instructions/how-to-submit/","text":"How to Submit Teams are expected to develop their solutions (ROS packages) in a 'solutions' folder inside the ~/catkin_ws/src directory. You may have one or more ROS packages in this folder for all your tasks. See figure below of expected directory structure: ~/catkin_ws/src \u251c\u2500\u2500 CMakeLists.txt \u251c\u2500\u2500 parc-engineers-league \u2502 \u251c\u2500\u2500 parc-robot \u2502 \u2502 \u251c\u2500\u2500 . \u2502 \u2502 \u251c\u2500\u2500 . \u2502 \u2502 \u251c\u2500\u2500 CMakeLists.txt \u2502 \u2502 \u2514\u2500\u2500 package.xml \u2502 \u251c\u2500\u2500 . \u2502 \u2514\u2500\u2500 . \u2514\u2500\u2500 YOUR_SOLUTION_FOLDER # Zip this folder and submit \u251c\u2500\u2500 your_ros_package1 \u2502 \u251c\u2500\u2500 . \u2502 \u251c\u2500\u2500 . \u2502 \u251c\u2500\u2500 CMakeLists.txt \u2502 \u2514\u2500\u2500 package.xml \u251c\u2500\u2500 your_ros_package2 \u2502 \u251c\u2500\u2500 . \u2502 \u251c\u2500\u2500 . \u2502 \u251c\u2500\u2500 CMakeLists.txt \u2502 \u2514\u2500\u2500 package.xml \u251c\u2500\u2500 . \u251c\u2500\u2500 . \u251c\u2500\u2500 . \u251c\u2500\u2500 . \u2514\u2500\u2500 README.md # Required Prepare a README.md file following this format and store in solution folder (see example ): Introduction Section: Briefly describe your approach Dependencies: List all the packages installed and used in your solution Task 1 - 3 description and run command(s) Challenges faced Include all the packages (dependencies) used in your solution in your package's \"package.xml\" file ( see guide ) Zip your solution folder and upload on the solution submission form","title":"How to Submit"},{"location":"phase1-instructions/how-to-submit/#how_to_submit","text":"Teams are expected to develop their solutions (ROS packages) in a 'solutions' folder inside the ~/catkin_ws/src directory. You may have one or more ROS packages in this folder for all your tasks. See figure below of expected directory structure: ~/catkin_ws/src \u251c\u2500\u2500 CMakeLists.txt \u251c\u2500\u2500 parc-engineers-league \u2502 \u251c\u2500\u2500 parc-robot \u2502 \u2502 \u251c\u2500\u2500 . \u2502 \u2502 \u251c\u2500\u2500 . \u2502 \u2502 \u251c\u2500\u2500 CMakeLists.txt \u2502 \u2502 \u2514\u2500\u2500 package.xml \u2502 \u251c\u2500\u2500 . \u2502 \u2514\u2500\u2500 . \u2514\u2500\u2500 YOUR_SOLUTION_FOLDER # Zip this folder and submit \u251c\u2500\u2500 your_ros_package1 \u2502 \u251c\u2500\u2500 . \u2502 \u251c\u2500\u2500 . \u2502 \u251c\u2500\u2500 CMakeLists.txt \u2502 \u2514\u2500\u2500 package.xml \u251c\u2500\u2500 your_ros_package2 \u2502 \u251c\u2500\u2500 . \u2502 \u251c\u2500\u2500 . \u2502 \u251c\u2500\u2500 CMakeLists.txt \u2502 \u2514\u2500\u2500 package.xml \u251c\u2500\u2500 . \u251c\u2500\u2500 . \u251c\u2500\u2500 . \u251c\u2500\u2500 . \u2514\u2500\u2500 README.md # Required Prepare a README.md file following this format and store in solution folder (see example ): Introduction Section: Briefly describe your approach Dependencies: List all the packages installed and used in your solution Task 1 - 3 description and run command(s) Challenges faced Include all the packages (dependencies) used in your solution in your package's \"package.xml\" file ( see guide ) Zip your solution folder and upload on the solution submission form","title":"How to Submit"},{"location":"phase1-instructions/task1/","text":"Task 1: Sidewalk following Delivery robots need to be able to navigate safely through street sidewalks as they move from pick up to drop off locations. In this task, we have simplified the sidewalk following problem by adding lanes to the sidewalk. Hence, teams are required to develop software to navigate the robot within the lanes from start to end position. Bear in mind that along with lane following, the robot would be required to avoid obstacles which may lie in its path. Task 1 Goal: The goal of this task is to autonomously control the delivery robot from the robot start position to a goal location on the sidewalk. To do this, you need to develop software which processes sensory information from the robots sensors (camera and LiDAR) and generates velocity commands to control the robot's motion [see here for details]. Task Guidelines Note Make sure you have completed the Getting Started Tutorials before starting the tasks. 1. Launching the Task In a new terminal, run the following launch file to bring up the delivery robot in Gazebo and RViz: roslaunch parc-robot task1.launch You should see the display below in Gazebo. To the right, there's the robot and to the left is the orange-red sphere which represents the goal location . 2. Explore Multiple Routes We have prepared two pre-defined routes you can use as you develop your solution. The default route is route1 , but you can select the second route option ( route2 ) by passing the argument in the roslaunch command as follows: roslaunch parc-robot task1.launch route:=route2 We recommend you play around with at least these two routes to ensure your solution is robust to different start locations. 3. Preparing your Solution Your solution should be prepared as ROS packages to be saved in your solution folder [link to how to submit]. Create a launch file in your ROS package which runs ALL the code you need in your solution. Name this launch file: task1_solution.launch . Hence, your solution to Task 1 should be run by calling the following commands simulatenously: In one terminal: roslaunch parc-robot task1.launch In another terminal: roslaunch your-package-name task1_solution.launch Note Ensure you DO NOT provide a solution with hard-coded positions for the robot to move to or hard-coded obstacle positions because in evaluation, the robot initial position and locations of obstacles (postbox, fire hydrant, etc.) would be randomized. Task Rules and Scoring The time-limit to complete this task is 5 minutes (300 secs) . The task is ONLY complete when ANY part of the robot is inside the orange-red sphere (goal location marker). Scoring for this task would be based on the following criteria: S/N Criteria / Metric Description 1 Out-of-lane distance Total distance traveled with any part of the robot lying outside the lane ( Smaller is better ) 2 Final travel distance to goal Shortest travel distance from robot (measured from robot center) to the goal which is calculated at the time limit [5 minutes] ( Smaller is better ) 3 Collisions Number of times the robot comes in contact with either obstacles, building, or walls ( Smaller is better ). 4 Completion time Time from launching the solution to task completion ( Smaller is better )","title":"Task 1: Sidewalk following"},{"location":"phase1-instructions/task1/#task_1_sidewalk_following","text":"Delivery robots need to be able to navigate safely through street sidewalks as they move from pick up to drop off locations. In this task, we have simplified the sidewalk following problem by adding lanes to the sidewalk. Hence, teams are required to develop software to navigate the robot within the lanes from start to end position. Bear in mind that along with lane following, the robot would be required to avoid obstacles which may lie in its path. Task 1 Goal: The goal of this task is to autonomously control the delivery robot from the robot start position to a goal location on the sidewalk. To do this, you need to develop software which processes sensory information from the robots sensors (camera and LiDAR) and generates velocity commands to control the robot's motion [see here for details].","title":"Task 1: Sidewalk following"},{"location":"phase1-instructions/task1/#task_guidelines","text":"Note Make sure you have completed the Getting Started Tutorials before starting the tasks.","title":"Task Guidelines"},{"location":"phase1-instructions/task1/#1_launching_the_task","text":"In a new terminal, run the following launch file to bring up the delivery robot in Gazebo and RViz: roslaunch parc-robot task1.launch You should see the display below in Gazebo. To the right, there's the robot and to the left is the orange-red sphere which represents the goal location .","title":"1. Launching the Task"},{"location":"phase1-instructions/task1/#2_explore_multiple_routes","text":"We have prepared two pre-defined routes you can use as you develop your solution. The default route is route1 , but you can select the second route option ( route2 ) by passing the argument in the roslaunch command as follows: roslaunch parc-robot task1.launch route:=route2 We recommend you play around with at least these two routes to ensure your solution is robust to different start locations.","title":"2. Explore Multiple Routes"},{"location":"phase1-instructions/task1/#3_preparing_your_solution","text":"Your solution should be prepared as ROS packages to be saved in your solution folder [link to how to submit]. Create a launch file in your ROS package which runs ALL the code you need in your solution. Name this launch file: task1_solution.launch . Hence, your solution to Task 1 should be run by calling the following commands simulatenously: In one terminal: roslaunch parc-robot task1.launch In another terminal: roslaunch your-package-name task1_solution.launch Note Ensure you DO NOT provide a solution with hard-coded positions for the robot to move to or hard-coded obstacle positions because in evaluation, the robot initial position and locations of obstacles (postbox, fire hydrant, etc.) would be randomized.","title":"3. Preparing your Solution"},{"location":"phase1-instructions/task1/#task_rules_and_scoring","text":"The time-limit to complete this task is 5 minutes (300 secs) . The task is ONLY complete when ANY part of the robot is inside the orange-red sphere (goal location marker). Scoring for this task would be based on the following criteria: S/N Criteria / Metric Description 1 Out-of-lane distance Total distance traveled with any part of the robot lying outside the lane ( Smaller is better ) 2 Final travel distance to goal Shortest travel distance from robot (measured from robot center) to the goal which is calculated at the time limit [5 minutes] ( Smaller is better ) 3 Collisions Number of times the robot comes in contact with either obstacles, building, or walls ( Smaller is better ). 4 Completion time Time from launching the solution to task completion ( Smaller is better )","title":"Task Rules and Scoring"},{"location":"phase1-instructions/task2/","text":"Task 2: Traffic sign detection and recognition Road crossing is inevitable for delivery robots as they navigate our streets to complete their delivery task. The task of road crossing is tricky even for humans to complete safely. A major component of the task is monitoring the traffic sign to ensure you comply with it. In this task, you are required to perform traffic sign detection and recognition. We have included a traffic sign with two states (RED and GREEN). Teams are required to develop software to use the on-board camera to detect and recognise the state of the traffic sign. Task 2 Goal: The goal of this task is to perform safe road crossing by detecting and recognising the state of the traffic sign and crossing only when the state is GREEN (GO). Task Guidelines Note Make sure you have completed the Getting Started Tutorials before starting the tasks. 1. Launching the Task In a new terminal, run the following launch file to bring up the delivery robot in Gazebo and RViz: roslaunch parc-robot task2.launch You should see the display below in Gazebo. The robot needs to cross the crosswalk and reach the orange-red sphere ( goal location ) on the other side. The traffic sign is initially set to RED and would change to GREEN after the start_delay duration is complete. 2. Explore Multiple Start Delays We have provided a simple way to set arbitrary values for the start_delay . This can be done by passing an argument as follows (e.g. we set it to 20 here): roslaunch parc-robot task2.launch start_delay:=20 While developing, we recommend you play around with different values for the start_delay to ensure your solution is robust. Also we recommend you consider setting a high start_delay value when running your solution to account for any code start delays when you launch your code. 3. Preparing your Solution Your solution should be prepared as ROS packages to be saved in your solution folder [link to how to submit]. Create a launch file in your ROS package which runs ALL the code you need in your solution. Name this launch file: task2_solution.launch . Hence, your solution to Task 2 should be run by calling the following commands simulatenously: In one terminal: roslaunch parc-robot task2.launch In another terminal: roslaunch your-package-name task2_solution.launch Note Ensure you DO NOT provide a solution with hard-coded move commands for the robot based on a particular start_delay value because in evaluation, the start_delay value would be randomized. Also, NO hacks for monitoring the state of the traffic sign would be allowed, you must use a vision-based approach ONLY. If the use of a hack is found out, you will receive a ZERO score for this task. Task Rules and Scoring The GO-time (time duration with signal on GREEN) is set to 15 secs . This means that you have ~15 secs to cross the road and reach the goal location. The task is ONLY complete when ANY part of the robot is inside the orange-red sphere (goal location marker). You are required to stop when you arrive at the goal location. Scoring for this task would be based on the following criteria: S/N Criteria / Metric Description 1 Reaction time Time between traffic sign state change to GREEN and when robot starts to move ( Smaller is better ) 2 Goal completion 1 if robot reached the goal location, 0 otherwise 3 Safe crossing 1 if robot is within the crosswalk ONLY when the signal is GREEN, 0 otherwise (i.e. 0 if robot is on crosswalk when signal is RED). 4 Completion time Time from launching the solution to task completion ( Smaller is better )","title":"Task 2: Traffic sign detection and recognition"},{"location":"phase1-instructions/task2/#task_2_traffic_sign_detection_and_recognition","text":"Road crossing is inevitable for delivery robots as they navigate our streets to complete their delivery task. The task of road crossing is tricky even for humans to complete safely. A major component of the task is monitoring the traffic sign to ensure you comply with it. In this task, you are required to perform traffic sign detection and recognition. We have included a traffic sign with two states (RED and GREEN). Teams are required to develop software to use the on-board camera to detect and recognise the state of the traffic sign. Task 2 Goal: The goal of this task is to perform safe road crossing by detecting and recognising the state of the traffic sign and crossing only when the state is GREEN (GO).","title":"Task 2: Traffic sign detection and recognition"},{"location":"phase1-instructions/task2/#task_guidelines","text":"Note Make sure you have completed the Getting Started Tutorials before starting the tasks.","title":"Task Guidelines"},{"location":"phase1-instructions/task2/#1_launching_the_task","text":"In a new terminal, run the following launch file to bring up the delivery robot in Gazebo and RViz: roslaunch parc-robot task2.launch You should see the display below in Gazebo. The robot needs to cross the crosswalk and reach the orange-red sphere ( goal location ) on the other side. The traffic sign is initially set to RED and would change to GREEN after the start_delay duration is complete.","title":"1. Launching the Task"},{"location":"phase1-instructions/task2/#2_explore_multiple_start_delays","text":"We have provided a simple way to set arbitrary values for the start_delay . This can be done by passing an argument as follows (e.g. we set it to 20 here): roslaunch parc-robot task2.launch start_delay:=20 While developing, we recommend you play around with different values for the start_delay to ensure your solution is robust. Also we recommend you consider setting a high start_delay value when running your solution to account for any code start delays when you launch your code.","title":"2. Explore Multiple Start Delays"},{"location":"phase1-instructions/task2/#3_preparing_your_solution","text":"Your solution should be prepared as ROS packages to be saved in your solution folder [link to how to submit]. Create a launch file in your ROS package which runs ALL the code you need in your solution. Name this launch file: task2_solution.launch . Hence, your solution to Task 2 should be run by calling the following commands simulatenously: In one terminal: roslaunch parc-robot task2.launch In another terminal: roslaunch your-package-name task2_solution.launch Note Ensure you DO NOT provide a solution with hard-coded move commands for the robot based on a particular start_delay value because in evaluation, the start_delay value would be randomized. Also, NO hacks for monitoring the state of the traffic sign would be allowed, you must use a vision-based approach ONLY. If the use of a hack is found out, you will receive a ZERO score for this task.","title":"3. Preparing your Solution"},{"location":"phase1-instructions/task2/#task_rules_and_scoring","text":"The GO-time (time duration with signal on GREEN) is set to 15 secs . This means that you have ~15 secs to cross the road and reach the goal location. The task is ONLY complete when ANY part of the robot is inside the orange-red sphere (goal location marker). You are required to stop when you arrive at the goal location. Scoring for this task would be based on the following criteria: S/N Criteria / Metric Description 1 Reaction time Time between traffic sign state change to GREEN and when robot starts to move ( Smaller is better ) 2 Goal completion 1 if robot reached the goal location, 0 otherwise 3 Safe crossing 1 if robot is within the crosswalk ONLY when the signal is GREEN, 0 otherwise (i.e. 0 if robot is on crosswalk when signal is RED). 4 Completion time Time from launching the solution to task completion ( Smaller is better )","title":"Task Rules and Scoring"},{"location":"phase1-instructions/task3/","text":"Task 3: Go-to-goal navigation The final task of this phase is to navigate safely through a park to reach the customer. The problem here is to navigate in an unconstrained but cluttered terrain without colliding with any obstacles. In this task you are required to move through a collision-free path to the goal using only your on-board sensors. Task 3 Goal: The goal of this task is to autonomously control the delivery robot from the robot start position to a goal location in the park without colliding with obstacles. To do this, you need to develop software which processes sensory information from the robots sensors (camera and LiDAR) and generates velocity commands to control the robot's motion [see here for details]. Task Guidelines Note Make sure you have completed the Getting Started Tutorials before starting the tasks. 1. Launching the Task In a new terminal, run the following launch file to bring up the delivery robot in Gazebo and RViz: roslaunch parc-robot task3.launch You should see the display below in Gazebo. To the right, there's the robot and to the left is the orange-red sphere (the goal location ) in front of the person. 2. Preparing your Solution Your solution should be prepared as ROS packages to be saved in your solution folder [link to how to submit]. Create a launch file in your ROS package which runs ALL the code you need in your solution. Name this launch file: task3_solution.launch . Hence, your solution to Task 3 should be run by calling the following commands simulatenously: In one terminal: roslaunch parc-robot task3.launch In another terminal: roslaunch your-package-name task3_solution.launch Note Ensure you DO NOT provide a solution with hard-coded positions for the robot to move to or hard-coded obstacle positions because in evaluation, the goal locations and locations of obstacles would be randomized. Task Rules and Scoring The time-limit to complete this task is 8 minutes (480 secs) . For The task is ONLY complete when ANY part of the robot is inside the orange-red sphere (goal location marker). You will be explicitly scored on the distance traveled, hence, do you best to follow the shortest path possible to the goal. Scoring for this task would be based on the following criteria: S/N Criteria / Metric Description 1 Final distance to goal Euclidean distance from robot (measured from robot center) to the goal which is calculated at the time limit [8 minutes] ( Smaller is better ) 2 Collisions Number of times the robot comes in contact with either obstacles, building, or walls ( Smaller is better ). 3 Completion time Time from launching the solution to task completion ( Smaller is better ) 4 Total travel distance Travel distance covered by the robot ( Smaller is better )","title":"Task 3: Go-to-goal navigation"},{"location":"phase1-instructions/task3/#task_3_go-to-goal_navigation","text":"The final task of this phase is to navigate safely through a park to reach the customer. The problem here is to navigate in an unconstrained but cluttered terrain without colliding with any obstacles. In this task you are required to move through a collision-free path to the goal using only your on-board sensors. Task 3 Goal: The goal of this task is to autonomously control the delivery robot from the robot start position to a goal location in the park without colliding with obstacles. To do this, you need to develop software which processes sensory information from the robots sensors (camera and LiDAR) and generates velocity commands to control the robot's motion [see here for details].","title":"Task 3: Go-to-goal navigation"},{"location":"phase1-instructions/task3/#task_guidelines","text":"Note Make sure you have completed the Getting Started Tutorials before starting the tasks.","title":"Task Guidelines"},{"location":"phase1-instructions/task3/#1_launching_the_task","text":"In a new terminal, run the following launch file to bring up the delivery robot in Gazebo and RViz: roslaunch parc-robot task3.launch You should see the display below in Gazebo. To the right, there's the robot and to the left is the orange-red sphere (the goal location ) in front of the person.","title":"1. Launching the Task"},{"location":"phase1-instructions/task3/#2_preparing_your_solution","text":"Your solution should be prepared as ROS packages to be saved in your solution folder [link to how to submit]. Create a launch file in your ROS package which runs ALL the code you need in your solution. Name this launch file: task3_solution.launch . Hence, your solution to Task 3 should be run by calling the following commands simulatenously: In one terminal: roslaunch parc-robot task3.launch In another terminal: roslaunch your-package-name task3_solution.launch Note Ensure you DO NOT provide a solution with hard-coded positions for the robot to move to or hard-coded obstacle positions because in evaluation, the goal locations and locations of obstacles would be randomized.","title":"2. Preparing your Solution"},{"location":"phase1-instructions/task3/#task_rules_and_scoring","text":"The time-limit to complete this task is 8 minutes (480 secs) . For The task is ONLY complete when ANY part of the robot is inside the orange-red sphere (goal location marker). You will be explicitly scored on the distance traveled, hence, do you best to follow the shortest path possible to the goal. Scoring for this task would be based on the following criteria: S/N Criteria / Metric Description 1 Final distance to goal Euclidean distance from robot (measured from robot center) to the goal which is calculated at the time limit [8 minutes] ( Smaller is better ) 2 Collisions Number of times the robot comes in contact with either obstacles, building, or walls ( Smaller is better ). 3 Completion time Time from launching the solution to task completion ( Smaller is better ) 4 Total travel distance Travel distance covered by the robot ( Smaller is better )","title":"Task Rules and Scoring"},{"location":"phase2-instructions/","text":"Phase 2: Physical Robot Note Phase 2 instructions are currently locked and would be available by May 28th 2021!","title":"Introduction"},{"location":"phase2-instructions/#phase_2_physical_robot","text":"Note Phase 2 instructions are currently locked and would be available by May 28th 2021!","title":"Phase 2: Physical Robot"}]}